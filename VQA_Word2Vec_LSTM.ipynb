{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VQA_Word2Vec_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5oizv5z4Bbq"
      },
      "source": [
        "# **LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeBnRuAN4GfS",
        "outputId": "b6d38924-c536-4a0f-86da-d9974702a4dd"
      },
      "source": [
        "#downloading load2vec model\n",
        "\n",
        "!python -m spacy download en_core_web_md\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (54.2.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrGPpm9JQxPu",
        "outputId": "a36d3a80-8a85-47a5-cdc2-fc86bcff3cd0"
      },
      "source": [
        "# importing spacy library and loading word2vec model\n",
        "\n",
        "import en_core_web_md\n",
        "nlp = en_core_web_md.load()\n",
        "print (\"Loaded WordVec\")\n",
        "\n",
        "# mounting the drive to access image features\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# %cd drive/My\\ Drive/vqa       \n",
        "# !ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded WordVec\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y0orkibQxSd"
      },
      "source": [
        "import sys, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from random import shuffle, sample\n",
        "import pickle as pk\n",
        "import gc\n",
        "import operator\n",
        "from collections import defaultdict\n",
        "from itertools import zip_longest\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import spacy\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl1kh7kCQxV4"
      },
      "source": [
        "def most_frequent_ans(training_questions, answer_train, images_train, upper_lim):\n",
        "    # Based on the treshold limit, this function returns tuple of lists of filtered questions, answers and imageIDs.\n",
        "    # It filters out the samples based on the frequency of occurance of the answer.\n",
        "    # Parameters:\n",
        "    # training_questions = training questions, answers_train = corresponding training answers,\n",
        "    # images_train = corresponding training imageIDs, upper_lim = number of answers/classes\n",
        "\n",
        "    freq_ans = defaultdict(int)\n",
        "    for ans in answer_train:\n",
        "        freq_ans[ans] += 1\n",
        "\n",
        "    sort_freq = sorted(freq_ans.items(), key=operator.itemgetter(1), reverse=True)[0:upper_lim]\n",
        "    top_ans, top_freq = zip(*sort_freq)\n",
        "    new_answers_train = list()\n",
        "    new_questions_train = list()\n",
        "    new_images_train = list()\n",
        "    for ans, ques, img in zip(answer_train, training_questions, images_train):\n",
        "        if ans in top_ans:\n",
        "            new_answers_train.append(ans)\n",
        "            new_questions_train.append(ques)\n",
        "            new_images_train.append(img)\n",
        "\n",
        "    return (new_questions_train, new_answers_train, new_images_train)\n",
        "\n",
        "def grouped(iterable, n, fillvalue=None):\n",
        "    # Groups the samples accorading to batch size and returns a zip object\n",
        "    # Parameters:\n",
        "    # iterable = samples to group, n = batch size, fillvalue = to fill empty values with\n",
        "    \n",
        "    args = [iter(iterable)] * n\n",
        "    return zip_longest(*args, fillvalue=fillvalue)\n",
        "\n",
        "def fetch_sum_of_answers(answers, encoder):\n",
        "    # Converts a class vector (integers) to binary class matrix and returns tensorflow object\n",
        "    # Parameters:\n",
        "    # answers = answers in string literals, encoder = a scikit-learn LabelEncoder object\n",
        "    \n",
        "    assert not isinstance(answers, str)\n",
        "    y = encoder.transform(answers)\n",
        "    nb_classes = encoder.classes_.shape[0]\n",
        "    Y = tf.keras.utils.to_categorical(y, nb_classes)\n",
        "    return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4ujOavkQ9aD"
      },
      "source": [
        "# Loading the training image feature pickle file\n",
        "import pickle as pk\n",
        "pkl_file = open('/content/drive/MyDrive/VQA/image_features.pkl', 'rb')\n",
        "features= pk.load(pkl_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCCCzjuzQ9c4"
      },
      "source": [
        "# Loading the testing image features pickle file\n",
        "pkl_file_val = open('/content/drive/MyDrive/VQA/image_features_val.pkl', 'rb')\n",
        "features_val = pk.load(pkl_file_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irdb4_NBQ9fz"
      },
      "source": [
        "def fetch_image_matrix_trian(img_list):\n",
        "  # Gets the 4096-dimensional CNN features for the given imageID and returns a numpy array of size (nb_samples, nb_dimensions)\n",
        "  # Parameters:\n",
        "  # img_list = list of imageIDs\n",
        "\n",
        "\timage_matrix = np.zeros((len(img_list), 4096))\n",
        "\tindex = 0\n",
        "\tfor id in img_list:\n",
        "\t\timage_matrix[index] = features['%012d' %(int(id))]\n",
        "\t\tindex = index + 1\n",
        "\treturn image_matrix\n",
        "\n",
        "def fetch_image_matrix_val(img_list):\n",
        "\t\n",
        "\t# Gets the 4096-dimensional CNN features for the given imageID and returns a numpy array of size (nb_samples, nb_dimensions)\n",
        "\t# Parameters:\n",
        "\t# img_list = list of imageIDs\n",
        "\n",
        "\timage_matrix = np.zeros((len(img_list), 4096))\n",
        "\tindex = 0\n",
        "\tfor id in img_list:\n",
        "\t\timage_matrix[index] = features_val['%012d' %(int(id))]\n",
        "\t\tindex = index + 1\n",
        "\treturn image_matrix\n",
        "\n",
        "def get_answers_matrix(answers, encoder):\n",
        "\t# Converts string objects to class labels and returns numpy array of shape (nb_samples, nb_classes)\n",
        "\t# Parameters:\n",
        "  # answers = asnwers in string format\n",
        "  # encoder = a scikit-learn LabelEncoder object\n",
        "\n",
        "\tassert not isinstance(answers, str)\n",
        "\ty = encoder.transform(answers) #string to numerical class\n",
        "\tnb_classes = encoder.classes_.shape[0]\n",
        "\tY = np_utils.to_categorical(y, nb_classes)\n",
        "\treturn Y\n",
        "\n",
        "def get_questions_tensor_timeseries(questions, nlp, timesteps):\n",
        "\t# Returns a time series of word vectors for tokens in the question as a numpy ndarray of shape: (nb_samples, timesteps, word_vec_dim)\n",
        "\t# Parameters:\n",
        "\t# questions = questions, nlp = word2vec model, timesteps = uniform length of question\n",
        "\t\n",
        "\tassert not isinstance(questions, str)\n",
        "\tnb_samples = len(questions)\n",
        "\tword_vec_dim = nlp(questions[0])[0].vector.shape[0]\n",
        "\tquestions_tensor = np.zeros((nb_samples, timesteps, word_vec_dim))\n",
        "\tfor i in range(len(questions)):\n",
        "\t\ttokens = nlp(questions[i])\n",
        "\t\tfor j in range(len(tokens)):\n",
        "\t\t\tif j<timesteps:\n",
        "\t\t\t\tquestions_tensor[i,j,:] = tokens[j].vector\n",
        "\treturn questions_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdVrguHoQ9jK",
        "outputId": "ff3c6fd7-57ef-47ee-c14c-146e2744a81d"
      },
      "source": [
        "#Loading dataset and necessary files\n",
        "\n",
        "training_questions     = open(\"/content/drive/MyDrive/VQA/ques_train.txt\",\"rb\").read().decode('utf8').splitlines()\n",
        "training_questions_len = open(\"/content/drive/MyDrive/VQA/ques_train_len.txt\",\"rb\").read().decode('utf8').splitlines()\n",
        "answers_train          = open(\"/content/drive/MyDrive/VQA/answer_train.txt\",\"rb\").read().decode('utf8').splitlines()\n",
        "images_train           = open(\"/content/drive/MyDrive/VQA/images_id.txt\",\"rb\").read().decode('utf8').splitlines()\n",
        "img_ids                = open('/content/drive/MyDrive/VQA/vgg_IDMap.txt').read().splitlines()\n",
        "\n",
        "sample(list(zip(images_train, training_questions, answers_train)), 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('163331', 'What sport is the athlete playing?', 'tennis'),\n",
              " ('94807', 'How is the pattern on his shirt?', 'plaid'),\n",
              " ('416776', 'What is on top of the pasta?', 'cheese'),\n",
              " ('4891',\n",
              "  'What is the purpose of the vehicle nearest the jet the photo was taken from?',\n",
              "  'baggage'),\n",
              " ('389793', 'What kind of flowers are those?', 'lilies')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuG9zXfcRJDu",
        "outputId": "6f33e9e5-476a-4357-c7d8-869cbd2c497a"
      },
      "source": [
        "# Garbage collection\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2-kyw4bQhde",
        "outputId": "1963046d-2e9e-4ae2-f58c-9b2d8184b2db"
      },
      "source": [
        "# Filtering the training dataset based on the number of classes and its frequency of occurance\n",
        "\n",
        "upper_lim = 1000 \n",
        "print (len(training_questions), len(answers_train),len(images_train))\n",
        "training_questions, answers_train, images_train = most_frequent_ans(training_questions, answers_train, images_train, upper_lim)\n",
        "training_questions_len, training_questions, answers_train, images_train = (list(t) for t in zip(*sorted(zip(training_questions_len, \n",
        "                                                                                                          training_questions, answers_train, \n",
        "                                                                                                          images_train))))\n",
        "print (len(training_questions), len(answers_train),len(images_train))\n",
        "\n",
        "# Getting unique answers and storing them in .sav file\n",
        "\n",
        "lbl = LabelEncoder()\n",
        "lbl.fit(answers_train)\n",
        "nb_classes = len(list(lbl.classes_))\n",
        "print(nb_classes)\n",
        "pk.dump(lbl, open('/content/drive/MyDrive/VQA/label_encoder_lstm.sav','wb'))\n",
        "\n",
        "\n",
        "# Hyperparameter tuning and model configurations\n",
        "\n",
        "batch_size               =      128\n",
        "img_dim                  =     4096\n",
        "word2vec_dim             =      300\n",
        "num_hidden_nodes_mlp     =     1024\n",
        "num_hidden_nodes_lstm    =      512\n",
        "num_layers_mlp           =        3\n",
        "num_layers_lstm          =        3\n",
        "dropout                  =       0.3\n",
        "activation_mlp           =     'tanh'\n",
        "num_epochs               =      4\n",
        "\n",
        "# Building the image model\n",
        "\n",
        "image_model = tf.keras.Sequential([tf.keras.layers.Reshape(input_shape = (img_dim,), target_shape=(img_dim,), name='Feeding_image_vectors_size_4096')], name='Image_Model')\n",
        "image_model.add(tf.keras.layers.Dense(num_hidden_nodes_mlp, kernel_initializer='uniform', name = 'Image_MLP_Hidden_layer_size_1024'))\n",
        "image_model.add(tf.keras.layers.Activation('tanh', name='Image_MLP_Activation_tanh'))\n",
        "image_model.add(tf.keras.layers.Dropout(0.5, name='Image_MLP_Dropout_0.5'))\n",
        "image_model.summary()\n",
        "\n",
        "# Building the question model\n",
        "\n",
        "language_model = tf.keras.Sequential([tf.keras.layers.LSTM(num_hidden_nodes_lstm,return_sequences=True, input_shape=(None, word2vec_dim), name='Feeding_question_vectors_to_LSTM_Layer_1'),\n",
        "                                      tf.keras.layers.LSTM(num_hidden_nodes_lstm, return_sequences=True, name='LSTM_layer_2')\n",
        "                                      ,tf.keras.layers.LSTM(num_hidden_nodes_lstm, return_sequences=False, name='LSTM_layer_3')\n",
        "                                      ], name = 'Language_Model')\n",
        "language_model.add(tf.keras.layers.Dense(num_hidden_nodes_mlp, kernel_initializer='uniform', name = 'Question_MLP_Hidden_layer_size_1024'))\n",
        "language_model.add(tf.keras.layers.Activation('tanh', name='Question_MLP_Activation_tanh'))\n",
        "language_model.add(tf.keras.layers.Dropout(0.5, name='Question_MLP_Dropout_0.5'))\n",
        "\n",
        "language_model.summary()\n",
        "\n",
        "# Concatenating image model and question model to build the final model\n",
        "\n",
        "upper_lim = 1000 #  \n",
        "\n",
        "merged=tf.keras.layers.concatenate([language_model.output,image_model.output], axis =-1, name='Merging_language_model_and_image_model')\n",
        "\n",
        "model =tf.keras.Sequential(name='CNN_LSTM_Model')(merged)\n",
        "model = tf.keras.layers.Dense(num_hidden_nodes_mlp, kernel_initializer='uniform', name = 'Combined_MLP_Hidden_layer_size_1024')(model)\n",
        "model = tf.keras.layers.Activation('tanh', name='Combined_MLP_Activation_tanh')(model)\n",
        "model = tf.keras.layers.Dropout(0.5, name='Combined_MLP_Dropout_0.5')(model)\n",
        "model = tf.keras.layers.Dense(upper_lim, name='Fully_Connected_Output_layer_size_1000')(model)\n",
        "out =   tf.keras.layers.Activation(\"softmax\", name='Softmax_Output_Probablities')(model)\n",
        "model = tf.keras.Model([language_model.input, image_model.input], out, name='LSTM_CNN_Model')\n",
        "\n",
        "# Compiling the model\n",
        "\n",
        "model.load_weights('/content/drive/MyDrive/VQA/Weights_Adam/LSTM_1000classes_epoch_16.hdf5')\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001),metrics=['acc'])\n",
        "#tf.keras.utils.plot_model(model, to_file='CNN_LSTM_model_v2.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "248349 248349 248349\n",
            "215407 215407 215407\n",
            "1000\n",
            "Model: \"Image_Model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Feeding_image_vectors_size_4 (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "Image_MLP_Hidden_layer_size_ (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "Image_MLP_Activation_tanh (A (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "Image_MLP_Dropout_0.5 (Dropo (None, 1024)              0         \n",
            "=================================================================\n",
            "Total params: 4,195,328\n",
            "Trainable params: 4,195,328\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"Language_Model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Feeding_question_vectors_to_ (None, None, 512)         1665024   \n",
            "_________________________________________________________________\n",
            "LSTM_layer_2 (LSTM)          (None, None, 512)         2099200   \n",
            "_________________________________________________________________\n",
            "LSTM_layer_3 (LSTM)          (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "Question_MLP_Hidden_layer_si (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "Question_MLP_Activation_tanh (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "Question_MLP_Dropout_0.5 (Dr (None, 1024)              0         \n",
            "=================================================================\n",
            "Total params: 6,388,736\n",
            "Trainable params: 6,388,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9iUwt_EMfoL"
      },
      "source": [
        "# **----------Training starts here----------**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqWPRAZb4KyC",
        "outputId": "c443d658-5acc-4aea-81c9-14b5bfbce84b"
      },
      "source": [
        "loss_epoch = []\n",
        "accuracy_epoch = []\n",
        "\n",
        "for k in range(num_epochs):\n",
        "    loss_per_epoch = 0\n",
        "    acc_per_epoch=0\n",
        "    progbar = tf.keras.utils.Progbar(len(training_questions))\n",
        "\n",
        "    index_shuffle = list(range(len(training_questions)))\n",
        "    shuffle(index_shuffle)\n",
        "    training_questions = [training_questions[i] for i in index_shuffle]\n",
        "    answers_train = [answers_train[i] for i in index_shuffle]\n",
        "    images_train = [images_train[i] for i in index_shuffle]\n",
        "\n",
        "    for ques_batch, ans_batch, im_batch in zip(grouped(training_questions, batch_size, \n",
        "                                                       fillvalue=training_questions[-1]), \n",
        "                                               grouped(answers_train, batch_size, \n",
        "                                                       fillvalue=answers_train[-1]), \n",
        "                                               grouped(images_train, batch_size, fillvalue=images_train[-1])):\n",
        "        timestep = len(nlp(ques_batch[-1]))\n",
        "        X_ques_batch = get_questions_tensor_timeseries(ques_batch, nlp, timestep)\n",
        "        X_ques_batch = np.array(X_ques_batch)\n",
        "        X_img_batch = fetch_image_matrix_trian(im_batch)\n",
        "        X_img_batch = np.array(X_img_batch) \n",
        "        Y_batch = fetch_sum_of_answers(ans_batch, lbl)\n",
        "        Y_batch = np.array(Y_batch)\n",
        "        loss = model.train_on_batch([X_ques_batch, X_img_batch], Y_batch)\n",
        "   \n",
        "        loss_per_epoch = loss_per_epoch + loss[0]\n",
        "        acc_per_epoch=acc_per_epoch + loss[1]\n",
        "     \n",
        "        progbar.add(batch_size, values=[('train loss', loss[0]), ('train acc',loss[1]),('epoch', k)]) \n",
        "        \n",
        "    if k%1 == 0:\n",
        "        model.save_weights(\"LSTM_1000classes\" + \"_epoch_{:02d}.hdf5\".format(k))\n",
        "\n",
        "    loss_epoch.append(loss_per_epoch)\n",
        "    np.save('loss.npy', np.array(loss_epoch))\n",
        "    accuracy_epoch.append(acc_per_epoch)\n",
        "    np.save('accuracy.npy', np.array(accuracy_epoch))\n",
        "\n",
        "model.save_weights(\"LSTM_1000classes\" + \"_epoch_{:02d}.hdf5\".format(k))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "215424/215407 [==============================] - 3747s 17ms/step - train loss: 2.1853 - train acc: 0.4791 - epoch: 0.0000e+00\n",
            "215424/215407 [==============================] - 3716s 17ms/step - train loss: 2.1665 - train acc: 0.4834 - epoch: 1.0000\n",
            "215424/215407 [==============================] - 3685s 17ms/step - train loss: 2.1567 - train acc: 0.4873 - epoch: 2.0000\n",
            "215424/215407 [==============================] - 3727s 17ms/step - train loss: 2.1459 - train acc: 0.4904 - epoch: 3.0000\n",
            "215424/215407 [==============================] - 3712s 17ms/step - train loss: 2.1329 - train acc: 0.4954 - epoch: 4.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSJkBFaa4K19",
        "outputId": "1f0bf1e1-f49d-4253-daee-bb972addb77c"
      },
      "source": [
        "# Loading the weights and compiling the model to test\n",
        "\n",
        "model.load_weights('LSTM_1000classes_epoch_03.hdf5') \n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001),metrics=['acc'])\n",
        "\n",
        "print (\"Model Loaded with Weights\")\n",
        "\n",
        "# Loading the testing dataset and related files\n",
        "\n",
        "val_imgs = open('/content/drive/MyDrive/VQA/val_images_id.txt','rb').read().decode('utf-8').splitlines()\n",
        "val_ques = open('/content/drive/MyDrive/VQA/ques_val.txt','rb').read().decode('utf-8').splitlines()\n",
        "val_ans  = open('/content/drive/MyDrive/VQA/answer_val.txt','rb').read().decode('utf-8').splitlines()\n",
        "print (len(val_ques), len(val_imgs),len(val_ans))\n",
        "\n",
        "# Filtering the testing dataset based on the number of answers and its frequency of occurance\n",
        "\n",
        "upper_lim = 1000 \n",
        "val_ques, val_ans, val_imgs = most_frequent_ans(val_ques, val_ans, val_imgs, upper_lim)\n",
        "print (len(val_ques), len(val_imgs),len(val_ans))\n",
        "\n",
        "# Loading the label encoder for classes\n",
        "\n",
        "label_encoder = pk.load(open('/content/drive/MyDrive/VQA/label_encoder_lstm.sav','rb'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Loaded with Weights\n",
            "121512 121512 121512\n",
            "105175 105175 105175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLdMzE3DMTwx"
      },
      "source": [
        "# **----------Testing starts here----------**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "y3YKJ3mHMPMd",
        "outputId": "5cd79529-760f-4cda-a422-703fd7fcd017"
      },
      "source": [
        "y_pred = []\n",
        "batch_size = 128 \n",
        "progbar = tf.keras.utils.Progbar(len(val_ques))\n",
        "for qu_batch,an_batch,im_batch in zip(grouped(val_ques, batch_size, \n",
        "                                                   fillvalue=val_ques[0]), \n",
        "                                           grouped(val_ans, batch_size, \n",
        "                                                   fillvalue=val_ans[0]), \n",
        "                                           grouped(val_imgs, batch_size, \n",
        "                                                   fillvalue=val_imgs[0])):\n",
        "    timesteps = len(nlp(qu_batch[-1]))\n",
        "    X_ques_batch = get_questions_tensor_timeseries(qu_batch, nlp, timesteps)\n",
        "\n",
        "    X_i_batch = fetch_image_matrix_val(im_batch)\n",
        "    \n",
        "    X_batch = [X_ques_batch, X_i_batch]\n",
        "    y_predict = model.predict(X_batch, verbose=0)\n",
        "    y_predict = np.argmax(y_predict,axis=1)\n",
        "    y_pred.extend(label_encoder.inverse_transform(y_predict))\n",
        "    progbar.add(batch_size)\n",
        "\n",
        "# Calculating the accuracy and saving the results in a text file\n",
        "\n",
        "correct_val = 0.0\n",
        "total = 0 \n",
        "\n",
        "correct_total = 0.0\n",
        "total = 0.0\n",
        "\n",
        "correct_yes_or_no = 0.0\n",
        "total_yes_or_no = 0.0\n",
        "\n",
        "correct_number = 0.0\n",
        "total_number = 0.0\n",
        "\n",
        "correct_other = 0.0\n",
        "total_other = 0.0\n",
        "\n",
        "f1 = open('res_v2_lstm_cnn_1000classes_70epoch.txt','w') \n",
        "\n",
        "for pred, truth, ques, img in zip(y_pred, val_ans, val_ques, val_imgs):\n",
        "    t_count = 0\n",
        "    for _truth in truth.split(';'):\n",
        "        if pred == truth:\n",
        "            t_count += 1 \n",
        "    if t_count >=1:\n",
        "        correct_val +=1\n",
        "    else:\n",
        "        correct_val += float(t_count)/3\n",
        "\n",
        "    total +=1\n",
        "\n",
        "    if truth == 'yes' or truth == 'no':\n",
        "      if pred == truth:\n",
        "        correct_yes_or_no += 1\n",
        "      total_yes_or_no += 1\n",
        "    \n",
        "    if truth.isnumeric():\n",
        "      if pred == truth:\n",
        "        correct_number += 1\n",
        "      total_number += 1\n",
        "    \n",
        "    else:\n",
        "      if pred == truth:\n",
        "        correct_other += 1\n",
        "      total_other += 1\n",
        "\n",
        "    try:\n",
        "        f1.write(str(ques))\n",
        "        f1.write('\\n')\n",
        "        f1.write(str(img))\n",
        "        f1.write('\\n')\n",
        "        f1.write(str(pred))\n",
        "        f1.write('\\n')\n",
        "        f1.write(str(truth))\n",
        "        f1.write('\\n')\n",
        "        f1.write('\\n')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print('Final Accuracy is ' + str(correct_val/total))\n",
        "print('Yes or no Accuracy is ' + str(correct_yes_or_no/total_yes_or_no))\n",
        "print('Number Accuracy is ' + str(correct_number/total_number))\n",
        "print('Other Accuracy is ' + str(correct_other/total_other))\n",
        "\n",
        "f1.write('Final Accuracy is ' + str(correct_val/total))\n",
        "f1.write('\\n')\n",
        "f1.write('Yes or no Accuracy is ' + str(correct_yes_or_no/total_yes_or_no))\n",
        "f1.write('\\n')\n",
        "f1.write('Number Accuracy is ' + str(correct_number/total_number))\n",
        "f1.write('\\n')\n",
        "f1.write('Other Accuracy is ' + str(correct_other/total_other))\n",
        "f1.write('\\n')\n",
        "\n",
        "f1.close()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# Loading the saved loss\n",
        "\n",
        "# loss1 = np.load('loss_1.npy').tolist()\n",
        "# loss18 = np.load('loss_18.npy').tolist()[1:]\n",
        "# loss36 = np.load('loss_36.npy').tolist()[1:]\n",
        "# loss54 = np.load('loss_54.npy').tolist()[1:]\n",
        "# # loss78 = np.load('weights_plot/loss_78.npy').tolist()\n",
        "\n",
        "# loss = loss1 + loss18 + loss36 + loss54 \n",
        "\n",
        "loss = np.load('loss.npy').tolist()\n",
        "acc = np.load('accuracy.npy').tolist()\n",
        "\n",
        "# Plotting the loss vs epoch graph\n",
        "\n",
        "e = np.arange(1, len(acc)+1, 1)\n",
        "\n",
        "plt.plot(e, acc)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy per epoch')\n",
        "plt.title('accuracy vs epoch')\n",
        "\n",
        "patch4 = mpatches.Patch(color = 'white',label='Model: CNN + LSTM')\n",
        "patch = mpatches.Patch(color = 'white',label='learning rate: 0.001')\n",
        "patch2 = mpatches.Patch(color = 'white',label='optimizer: Adam') \n",
        "patch3 = mpatches.Patch(color = 'white',label='No. of training samples: 215407')\n",
        "\n",
        "plt.legend(handles=[patch4,patch, patch2,patch3])\n",
        "plt.show()\n",
        "plt.savefig('CNN_LSTM_LOSS')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105216/105175 [==============================] - 1361s 13ms/step\n",
            "Final Accuracy is 0.47860232945091513\n",
            "Yes or no Accuracy is 0.6708783147568266\n",
            "Number Accuracy is 0.2917737789203085\n",
            "Other Accuracy is 0.505475861618941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3iUVfbA8e8hhBJ6FwidUAIJARI6SBMQXaq0RaUsRSwoIpYFAXuBdV1YUFEElSZFii4qHURBCBCqSOiQICXUEAJJOL8/ZphfggEGZJiU83mePM7bz0QyZ95773uuqCrGGGMMQBZvB2CMMSbtsKRgjDHGxZKCMcYYF0sKxhhjXCwpGGOMcbGkYIwxxsWSgjHmhkRkqoi86e04zL1jScEYY4yLJQWTaYmD/Q0Yk4z9QRivEpGXRWSfiFwQkV0i0vG67f1F5Ldk22s515cSkW9E5KSIxIjIf53rR4vItGTHlxURFZGszuVVIvKWiPwMxAHlRaRPsmvsF5GB18XQXkQiROS8M9Y2ItJFRDZdt9/zIrIwlffYTUTCr1s3REQWOV+3db63CyISJSIv3OT31dcZ6xkR+VFEyiTbpiIy2PkeTonImGtJT0SyiMgIETkkIidE5EsRyZfs2EYi8ouInBWRIyLSO9llC4jI/5zx/SoiFW4Un8kAVNV+7MdrP0AXoASOLyjdgItA8WTbooAwQICKQBnAB9gK/BvIBeQAGjmPGQ1MS3b+soACWZ3Lq4DDQDUgK+ALPARUcF7jfhzJopZz/zrAOeABZ4wlgSpAduA0UDXZtbYAnVN5j37ABSAg2bqNQHfn62NAY+frAteuncp52gN7garO2EcAvyTbrsBKoCBQGtgD9HNu6+s8tjyQG/gG+Mq5rYwzvh7O30chIMS5bSoQ4/w9ZAWmA7O8/e/Gfjz34/UA7Md+kv8AEUB75+sfgWdT2ac+cPLaB/1129xJCq/fIoYF164LfAL8+wb7fQS85XxdDTgDZL/BvtOAkc7XAc4PYT/n8mFgIJD3FnF9D/wj2XIWZwIr41xWoE2y7U8Cy52vlwNPJttWGUhwftC/Asy/wTWnAp8lW24L7Pb2vxP78dyPNR8ZrxKRx51NM2dF5CxQHSjs3FwK2JfKYaWAQ6qaeIeXPXJdDA+KyHoROe2Moa0bMQB8AfxdRAR4DJitqpdvsO8MHN/EAf4OLFDVOOdyZ+c1D4nIahGpf4NzlAH+k+x3dRrH3U3JG7y3QzjuwnD+99B127ICxW7xHgH+SPY6DsedhsmgLCkYr3G2h38KPA0UUtX8wA4cH3Tg+IBLrf36CFD6Wj/BdS7iaK655r5U9nGVBhaR7MA8YCxQzBnDYjdiQFXXA1eAxjg+6L9KbT+npUAREQnBkRxmJDvPRlVtDxTFcZcy+wbnOAIMVNX8yX5yquovyfYplex1aSDa+ToaR1JJvi0ROH6z92gyH0sKxpty4fiAPgkgIn1w3Clc8xnwgojUdo4UquhMJBtwtMO/KyK5RCSHiDR0HhMBNBGR0s6O1FduEUM2HP0DJ4FEEXkQaJVs+2Sgj4i0cHbWlhSRKsm2fwn8F0hQ1bU3uoiqJgBzgDE42vyXOt9zNhHpKSL5nPucB67e4DQfA6+ISDXnsflEpMt1+wwTkQIiUgp4FvjauX4mMEREyolIbuBt4Gvn3dZ0oKWIdBWRrCJSyJm8TCZkScF4jaruAv4FrMPxjTUI+DnZ9jnAWzi+VV/A8S26oKomAX/D0fF8GDiKo5MaVV2K44NwG7AJ+O4WMVwABuP4dn4Gxzf+Rcm2bwD64OjUPgesJuU37q9wJLJp3NoMoCUw57qmr8eAgyJyHngC6HmDWOcD7wGznPvuAB68breFON53BPA/HEkN4HNnrGuAA0A88IzzvIdxNF8NxdEkFQHUcOP9mAxIVG2SHWPulIjkBE7gGDEU6eVYFMcIp73ejMOkb3anYMxfMwjY6O2EYMzdklpHnTHGDSJyEEeHdAcvh2LMXePROwXnU5s7RWSHiMx0dghOFpGtIrJNROY6O70Qkd7ieDo1wvnTz5OxGfNXqWpZVS2jqlu8HQuAqoo1HZm/ymN9CiJSElgLBKrqJRGZjWOo3zeqet65zwfACVV91/lYfaiqPu2RgIwxxtySp5uPsgI5RSQBx9jx6GQJQYCcJBszfrsKFy6sZcuWvRtxGmNMprFp06ZTqloktW0eSwqqGiUiY3EMGbwELFHVJQAiMgXHELhdOIbBXdNZRJrgqNkyRFWPXHdaRGQAMACgdOnShIeHX7+LMcaYmxCRQzfa5rE+BREpgKOAVzkcj9jnEpFHAVS1j3PdbzjHlwPfAmVVNRjHgz1fpHZeVZ2kqqGqGlqkSKqJzhhjzB3yZEdzS+CAqp50Pqn5DdDg2kbnA0izcNR9QVVjktWN+Qyo7cHYjDHGpMKTSeEwUE9E/Jz9By2A30SkIrj6FNoBu53LxZMd2w7HXYQxxph7yJN9Cr+KyFxgM47CW1uAScAKEcmLY3z3VhwP/wAMFpF2zn1PA73v5LoJCQkcPXqU+Pj4v/gOjEn/cuTIgb+/P76+vt4OxaQT6brMRWhoqF7f0XzgwAHy5MlDoUKFcNyMGJM5qSoxMTFcuHCBcuXKeTsck4aIyCZVDU1tW4YrcxEfH28JwRhARChUqJDdNZvbkuGSAmAJwRgn+1swtytDJgVjjMmorl5Vxi+PZEfUOY+c35KCB4gIjz76qGs5MTGRIkWK8PDDD9/WecqWLcupU6f+8j4AY8eOpUqVKoSEhBAWFsaXX34JQNOmTQkN/f+mxfDwcJo2bQrAqlWrEBG+/fZb1/aHH36YVatW3db7uN7BgwepXr36n9avX7+eunXrEhISQtWqVRk9ejRTpkwhJCSEkJAQsmXLRlBQECEhIbz88stMnToVEWHZsmWucyxYsAARYe7cuX8pRmPSonOXEuj/ZTj/WrqH77Yd88g1LCl4QK5cudixYweXLl0CYOnSpZQsWfIWR3nOxx9/zNKlS9mwYQMREREsX76c5AMMTpw4wffff5/qsf7+/rz11lu3db07LT3Sq1cvJk2aREREBDt27KBr16706dOHiIgIIiIiKFGiBCtXriQiIoJ3330XgKCgIGbNmuU6x8yZM6lRw+aHMRnP7j/O0+6/a1m95ySvt6/GS20qe+Q6lhQ8pG3btvzvf/8DHB9UPXr0cG07ffo0HTp0IDg4mHr16rFt2zYAYmJiaNWqFdWqVaNfv34pPrinTZtGnTp1CAkJYeDAgSQlJbkdy9tvv81HH31E3rx5AcibNy+9evVybR82bNgNP/hr1KhBvnz5WLp0qftv/g6dOHGC4sUdj6v4+PgQGBh4y2MaN27Mhg0bSEhIIDY2lr179xISYjNJmoxlYUQUHSf8wqUrScwaUI/H65f1WH+RJQUP6d69O7NmzSI+Pp5t27ZRt25d17ZRo0ZRs2ZNtm3bxttvv83jjz8OwGuvvUajRo3YuXMnHTt25PDhwwD89ttvfP311/z8889ERETg4+PD9OnT/3TNtm3bEh0dnWLd+fPnuXDhAuXLl79hrPXr1ydbtmysXLky1e3Dhw/nzTffvO3fwe0aMmQIlStXpmPHjnzyySdujZoREVq2bMmPP/7IwoULadeuncfjNOZeSUi6yhvf7eLZWRFUL5mX755pRGjZgh69piUFDwkODubgwYPMnDmTtm3bpti2du1aHnvsMQCaN29OTEwM58+fZ82aNa6+iIceeogCBQoAsHz5cjZt2kRYWBghISEsX76c/fv3/+maixcvpkSJEncU74gRI274wd+kSRNX3Dfy1ltvudr+o6OjXa+feuopt2MYOXIk4eHhtGrVihkzZtCmTRu3jruWgGfNmpXijsyY9Ozkhcv0/OxXJq89QO8GZZnRvx5F8+bw+HVt5jUPateuHS+88AKrVq0iJibmjs+jqvTq1Yt33nnnto/NmzcvuXPnZv/+/Te9W2jevDkjRoxg/fr1qW6/dreQNWvq/2SGDx/O8OHDAUefQkRExG3HClChQgUGDRpE//79KVKkCDExMRQqVOimx9SpU4ft27fj5+dHpUqV7ui6xqQlmw+fYdC0TZy7lMCH3ULoUPPe9UnanYIH9e3bl1GjRhEUFJRifePGjV3NP6tWraJw4cLkzZuXJk2aMGPGDAC+//57zpw5A0CLFi2YO3cuJ06cABx9EocO3bDy7Z+88sorPPXUU5w/fx6A2NhY1+ij5EaMGMH777+f6jlatWrFmTNnXP0fnvC///3P1Y8SGRmJj48P+fPnd+vYd999l7fffttjsRlzL6gq09Yfotsn68ie1YdvBjW8pwkB7E7Bo/z9/Rk8ePCf1o8ePZq+ffsSHByMn58fX3zhqBI+atQoevToQbVq1WjQoAGlS5cGIDAwkDfffJNWrVpx9epVfH19mTBhAmXKlElx3rZt2/LZZ5/9qQlp0KBBxMbGEhYWhq+vL76+vgwdOpTrtW3blpuVIx8+fDjt27e/7d9Dan7//Xf8/f1dy//+97+ZN28eQ4YMwc/Pj6xZszJ9+nR8fHzcOt+DDz54V+IyxlviE5J4dcEO5mw6StPKRfhPt5rk87v3NasyXO2j3377japVq3opImPSHvubSPuOnonjiWmb2BF1nsEtAniuRQBZsnjuafSb1T6yOwVjjPGinyJPMnjmFhKvKp89HkrLwGJejceSgjHGeIGq8tHqfYz98XcCiubh48dqU65wLm+HZUnBGGPutQvxCbwwZys/7jzO32qU4L3OQfhlSxsfx2kjCmOMyST2nrjAgK82cSgmjhEPVeUfjcqlqWq2lhSMMeYe+X77MV6Ys5Wc2XyY9o+61K9w82dwvMGSgjHGeFhi0lXGLtnDx6v3EVIqPx89Wovi+XJ6O6xU2cNrHpA7d26PX+Pjjz9O9QE0T1qwYAG7du36S+f44osvCAgIICAgwPV8xvVOnz7NAw88QEBAAA888IDrIT5VZfDgwVSsWJHg4GA2b97sOqZNmzbkz5//tsuTG+Nppy9eodeUDXy8eh8965bm64H10mxCAEsKadrNKqE+8cQTrkJ69+qafzUpnD59mtdee41ff/2VDRs28Nprr7k+8JN79913adGiBZGRkbRo0cJVJvv7778nMjKSyMhIJk2axKBBg1zHDBs2jK+++uqOYzPGE7YdPcvfxq9l48EzvP9IMG91DCJ7VvceyPQWSwoeNmbMGMLCwggODmbUqFGu9R06dKB27dpUq1aNSZMmudbnzp2boUOHUqNGDdatW0fu3LkZPnw4NWrUoF69ehw/fhxwPBU9duxYwDFRzksvvUSdOnWoVKkSP/30EwBxcXF07dqVwMBAOnbsSN26dbn+YT9w1Cp66aWXqFWrFnPmzOHTTz8lLCyMGjVq0LlzZ+Li4vjll19YtGgRw4YNIyQkhH379rFv3z7atGlD7dq1ady4Mbt3777p7+LHH3/kgQceoGDBghQoUIAHHniAH3744U/7LVy40FXau1evXixYsMC1/vHHH0dEqFevHmfPnuXYMcdEIy1atCBPnjxu/38xxtNmbzzCIx+vA2DeEw3oGlrKyxG5x5KCBy1ZsoTIyEjX5DabNm1izZo1AHz++eds2rSJ8PBwxo0b5yqYd/HiRerWrcvWrVtp1KgRFy9epF69emzdupUmTZrw6aefpnqtxMRENmzYwIcffshrr70GwMSJEylQoAC7du3ijTfeYNOmTTeMtVChQmzevJnu3bvTqVMnNm7cyNatW6latSqTJ0+mQYMGtGvXjjFjxhAREUGFChUYMGAA48ePZ9OmTYwdO5Ynn3wSgEWLFjFy5Mg/XSMqKopSpf7/D8Pf35+oqKg/7Xf8+HHXvAr33XefKxG6e7wx3nQ5MYlXvtnOi/O2UadsQb59phFB/vm8HZbbrKPZg5YsWcKSJUuoWbMm4ChEFxkZSZMmTRg3bhzz588H4MiRI0RGRlKoUCF8fHzo3Lmz6xzZsmVztZPXrl37hpPddOrUybXPwYMHAUep62effRaA6tWrExwcfMNYu3Xr5nq9Y8cORowYwdmzZ4mNjaV169Z/2j82NpZffvmFLl26uNZdvnwZcFSHvVvzGohImhquZ8zNHDt3iSembWbrkbMMalqBF1pVxseD5So8wZKCB6kqr7zyCgMHDkyxftWqVSxbtox169bh5+dH06ZNXRPK5MiRI0UROF9fX9eHoo+PD4mJialeK3v27Lfc52Zy5fr/Jyl79+7NggULqFGjBlOnTk11TuarV6+SP3/+2yqRXbJkyRTnOnr0qGs+6OSKFSvGsWPHKF68OMeOHaNo0aKu448cOZLieG9Oc2pMcuv2xfD0jM3EJyTx8aO1aFO9uLdDuiPWfORBrVu35vPPPyc2NhZwNH+cOHGCc+fOUaBAAfz8/Ni9e/cN5zD4qxo2bMjs2bMB2LVrF9u3b3fruAsXLlC8eHESEhJSzPCWJ08eLly4ADjmaShXrhxz5swBHAlw69atNz1v69atWbJkCWfOnOHMmTMsWbIk1buQdu3auUYmffHFF67KrO3atePLL79EVVm/fj358uVzNTMZ4y2qymc/7efRyb+S38+XhU83TLcJASwpeFSrVq34+9//Tv369QkKCuKRRx7hwoULtGnThsTERKpWrcrLL79MvXr1PHL9J598kpMnTxIYGMiIESOoVq0a+fLdum3zjTfeoG7dujRs2JAqVaq41nfv3p0xY8ZQs2ZN9u3bx/Tp05k8eTI1atSgWrVqLFy4ELhxn0LBggV59dVXCQsLIywsjJEjR1KwoGNqwX79+rk6wV9++WWWLl1KQEAAy5Yt4+WXXwYcpb3Lly9PxYoV6d+/PxMnTnSdu3HjxnTp0oXly5fj7+/Pjz/+eOe/OGPcdPFyIs/M3MKb//uNllWLsuCphlQsmr4HPFjp7AwsKSmJhIQEcuTIwb59+2jZsiW///472bJl83Zo5h6yvwnPOHDqIgO/CmfviViGta7CE/eXTzf9X14rnS0iQ4B+gALbgT7ABCAUEGAP0FtVY0UkO/AlUBuIAbqp6kFPxpfRxcXF0axZMxISElBVJk6caAnBmLtg2a7jDPk6gqw+whd969A44MaTU6U3HksKIlISGAwEquolEZkNdAeGqOp55z4fAE8D7wL/AM6oakUR6Q68B3RL/ezGHXny5En1uQRjzJ1Juqp8uGwP41fsJahkPj56tBb+Bfy8HdZd5enRR1mBnCKSAPgB0ckSggA5cdxFALQHRjtfzwX+KyKi6bl9yxiTYZyNu8KzsyJYveckXWr780aH6uTwTdtPJ98JjyUFVY0SkbHAYeASsERVlwCIyBSgLbALuDZZcEngiPPYRBE5BxQCTiU/r4gMAAYArjmMjTHGk3ZGn+OJaZv441w8b3Wszt/rlE43/Qe3y2Ojj0SkAI5v/+WAEkAuEXkUQFX7ONf9xm02EanqJFUNVdXQm00yb4wxd8P8LUfpNPEXEhKVrwfWp2fdMhk2IYBnh6S2BA6o6klVTQC+ARpc26iqScAs4Nrju1FAKQARyQrkw9HhbIwx99yVxKuMXrSTIV9vJaRUfr59phG1Shfwdlge58mkcBioJyJ+zv6DFsBvIlIRXH0K7YBrVdQWAb2crx8BVmSW/oQPP/yQuLg413Lbtm05e/as28cvWrTIVUnUkyIiIhCRVIvYXdO7d2/mzp3r8ViM8aQT5+P5+6frmfrLQfo1Kse0fnUpkie7t8O6JzyWFFT1VxwdxptxDEfNAkwCvhCR7c51xYHXnYdMBgqJyF7geeBlT8WW1lyfFBYvXkz+/PndPr5du3auB7zulDulMWbOnEmjRo2YOXPmX7qWMWlZ+MHTPDR+LTujzzOuR01GPByIr0/mec7Xo+9UVUepahVVra6qj6nqZVVtqKpBznU9r41GUtV4Ve2iqhVVtY6q7vdkbJ70wQcfUL16dapXr86HH34IwMGDB6lSpQo9e/akatWqPPLII8TFxTFu3Diio6Np1qwZzZo1AxylrE+dOuU6pnfv3lSqVImePXuybNkyGjZsSEBAABs2bABg6tSpPP300wCEhIS4fnLmzMnq1au5ePEiffv2pU6dOtSsWdP15PHUqVNp164dzZs3p0WLFjd9T6rKnDlzmDp1KkuXLnXValJVnn76aSpXrkzLli05ceKE65jXX3+dsLAwqlevzoABA7h249e0aVOGDBlCaGgoVatWZePGjXTq1ImAgABGjBhxF/9PGOM+VeWLXw7SfdJ6cmXzYf5TDWhXo4S3w7r3VDXd/tSuXVuvt2vXrj+tu5fCw8O1evXqGhsbqxcuXNDAwEDdvHmzHjhwQAFdu3atqqr26dNHx4wZo6qqZcqU0ZMnT7rOcW35wIED6uPjo9u2bdOkpCStVauW9unTR69evaoLFizQ9u3bq6rqlClT9KmnnkoRx6JFi7RRo0Z65coVfeWVV/Srr75SVdUzZ85oQECAxsbG6pQpU7RkyZIaExOjqqpRUVH64IMPpvq+1q5dq82bN1dV1R49eujcuXNVVXXevHnasmVLTUxM1KioKM2XL5/OmTNHVdV1XlXVRx99VBctWqSqqvfff7+++OKLqqr64YcfavHixTU6Olrj4+O1ZMmSeurUqTv99ZtUePtvIj2Iu5yoz83aomVe+k77TtmgZ+OueDskjwLC9Qafq5nnnugeWbt2LR07diRXrlzkzp2bTp06uSa9KVWqFA0bNgTg0UcfZe3atbc8X7ly5QgKCiJLlixUq1aNFi1aICIEBQW5SmRfLzIykmHDhjF79mx8fX1ZsmQJ7777LiEhIa6KrIcPHwZwTXoDUKJECRYvXpzqOWfOnEn37t0BRw2ka01Ia9asoUePHvj4+FCiRAmaN2/uOmblypXUrVuXoKAgVqxYwc6dO13brpXWDgoKolq1ahQvXpzs2bNTvnz5FJVQjfG0wzFxdProFxZERDGkZSU+fTyUfDl9vR2W11jp7Hvo+mFs7gxru1YSGyBLliyu5SxZsqTaDxAbG0vXrl359NNPXRVEVZV58+ZRuXLlFPv++uuvKUpm30hSUhLz5s1j4cKFvPXWW6gqMTExroqpqYmPj+fJJ58kPDycUqVKMXr0aFeTU/L3lfw93ex9GeMJK38/wXOzIlBVPu8VRrMqRb0dktfZncJd1rhxYxYsWEBcXBwXL15k/vz5NG7cGIDDhw+zbp1jer4ZM2bQqFEjIGVJ6r+qb9++9OnTx3VNcJSsHj9+vKtNf8uWLbd1zuXLlxMcHMyRI0c4ePAghw4donPnzsyfP58mTZrw9ddfk5SUxLFjx1i5ciWAKwEULlyY2NhYG5Fk0pSrV5XxyyPpO3UjxfPl4NtnGllCcLKkcJfVqlWL3r17U6dOHerWrUu/fv1cM69VrlyZCRMmULVqVc6cOeOaeH7AgAG0adPG1dF8pw4dOsTcuXP5/PPPXZ3N4eHhvPrqqyQkJBAcHEy1atV49dVXUz0+Ojqatm3b/mn9zJkz6dixY4p1nTt3dq0PCAggMDCQxx9/nPr16wOQP39++vfvT/Xq1WndujVhYWF/6b0Zc7ecj09gwFfh/GvpHtrXKMH8JxtSptCt75gzCyudfY8cPHiQhx9+mB07dng7FJPJpNW/CW/4/Y8LPDFtE0dOxzHioar0alA2Qz+dfCNeK51tjDFpxXfbonlx7jZyZc/KzAH1CCtb0NshpUmWFO6RsmXL2l2CMV6QmHSV937Yzac/HaB2mQJM7FmLYnlzeDusNMuSgjEmwzoVe5mnZ2xm/f7TPF6/DCMeCiRbVutKvRlLCsaYDGnL4TMMmraZM3FX+FeXGnSu7e/tkNIFSwrGmAxFVZm54QijF+2kaN7szBvUgOol83k7rHTDkoIxJsOIT0hi5MIdzA4/SpNKRfhPtxAK5LJ5yW+HNa55gIgwdOhQ1/LYsWMZPXr0Xb9Ojx49CA4O5t///neK9QsWLGDXrl23fT53SnBHR0fzyCOP3Pa5ve3gwYNUr179rp7zgw8+IDAwkODgYFq0aMGhQ4dc29q0aUP+/Pl5+OGHUxzTu3dvypUr53qOJCIiIsX2jRs3kjVr1hQP+33xxRcEBAQQEBDAF198AcCFCxdSFD8sXLgwzz333F19f+lN1NlLdP1kHbPDj/J0s4pM6R1mCeFO3KgoUnr4SYsF8VRVs2fPrmXLlnUVuRszZoyOGjXqrl7j2LFjWqFChVS39erVy1WU7noJCQl3NY704sCBA1qtWrW7es4VK1boxYsXVVV14sSJ2rVrV9e2ZcuW6aJFi/Shhx5KcczN/t8kJiZqs2bN9MEHH0xRVLBcuXIaExOjp0+f1nLlyunp06f/dGytWrV09erVqZ43LfxNeNrayJNa8/UlWm3kD/rjjmPeDifNwwri3VtZs2ZlwIABf/oGD45vrM2bN3d9u7xWmO5G4uPj6dOnD0FBQdSsWdNVRqJVq1ZERUUREhLiKrgH8Msvv7Bo0SKGDRtGSEgI+/bto2nTpjz33HOEhobyn//8h2+//Za6detSs2ZNWrZsyfHjx4GUJbh79+7N4MGDadCgAeXLl3d9c03+jXvq1Kl06tSJNm3aEBAQwIsvvuiKY/LkyVSqVIk6derQv39/13mTW716teubbs2aNblw4QKxsbG0aNGCWrVqERQU5Crz7W4Z8dGjR/PYY49Rv359AgIC+PTTT/903aSkJIYNG0ZYWBjBwcF88sknABw7dowmTZoQEhJC9erVU/xeU9OsWTP8/PwAqFevHkePHnVta9GiBXny5Lnp8dcbP348nTt3pmjR/y+38OOPP7qKFhYoUIAHHnjgT5Mc7dmzhxMnTqQobZJZqCofr97HY5N/pVCubCx8uiGtqt3n7bDSNUsKHvLUU08xffp0zp07l2L9M888Q69evdi2bRs9e/Zk8ODBNz3PhAkTEBG2b9/OzJkz6dWrF/Hx8SxatIgKFSoQERGR4sOgQYMGtGvXjjFjxhAREUGFChUAuHLlCuHh4QwdOpRGjRqxfv16tmzZQvfu3Xn//fdTvfaxY8dYu3Yt33333Q0n8YmIiODrr79m+/btfP311xw5coTo6GjeeDBF6TEAACAASURBVOMN1q9fz88//8zu3btTPXbs2LFMmDCBiIgIfvrpJ3LmzEmOHDmYP38+mzdvZuXKlQwdOtRVs2nv3r0MHTqU3bt3s3v3bmbMmMHatWsZO3Ysb7/9tuu827ZtY8WKFaxbt47XX3+d6OjoFNedPHky+fLlY+PGjWzcuJFPP/2UAwcOMGPGDFq3bk1ERARbt24lJCQEgH79+nH9k/PXmzx5Mg8++OBN97lm+PDhBAcHM2TIEC5fvgxAVFQU8+fPd5U+uSYqKopSpUq5lv39/YmKikqxz6xZs+jWrVumezI39nIiT07fzLvf7+bB6sVZ8FRDKhTJ7e2w0j3raPaQvHnz8vjjjzNu3Dhy5szpWr9u3Tq++eYbAB577LEU365Ts3btWp555hkAqlSpQpkyZdizZw958+a9rXi6devmen306FG6devGsWPHuHLlCuXKlUv1mA4dOpAlSxYCAwNddxPXa9GiBfnyOUZ2BAYGcujQIU6dOsX999/vKsndpUsX9uzZ86djGzZsyPPPP0/Pnj3p1KkT/v7+JCQk8M9//pM1a9aQJUsWoqKiXNe+VkYcuGkZ8fbt25MzZ05y5sxJs2bN2LBhg+sDHmDJkiVs27bNdfdz7tw5IiMjCQsLo2/fviQkJNChQwfXMZ999tlNf7fTpk0jPDyc1atX33Q/gHfeeYf77ruPK1euMGDAAN577z1GjhzJc889x3vvvUeWLLf/PW3WrFl89dVXt31cerb3RCxPTNvE/pOxDG9blX6Ny2W6pOgpdqfgQc899xyTJ0/m4sWL3g4lRYnsZ555hqeffprt27fzySefpChpnVzyktbXvq3fbB8fH5/bKnv98ssv89lnn3Hp0iUaNmzI7t27mT59OidPnmTTpk1ERERQrFgxV3zulhG/VYlyVWX8+PFEREQQERHBgQMHaNWqFU2aNGHNmjWULFmS3r178+WXX97yPSxbtoy33nqLRYsWpYjvRooXL46IkD17dvr06eNq9goPD6d79+6ULVuWuXPn8uSTT7JgwQJKliyZYn6Jo0ePUrJkSdfy1q1bSUxMpHbt2re8dkbxw44/6DDhZ05fvMK0f9Slf5PylhDuIksKHlSwYEG6du3K5MmTXesaNGjArFmzAJg+ffot24EbN27M9OnTAUfb8eHDh/80L8L1blWK+9y5c64PlmujWe6msLAwVq9ezZkzZ0hMTGTevHmp7rdv3z6CgoJ46aWXCAsLY/fu3Zw7d46iRYvi6+vLypUrU4zocdfChQuJj48nJiaGVatW/alCa+vWrfnoo49ISEgAHL/XixcvcujQIYoVK0b//v3p168fmzdvvul1tmzZwsCBA1m0aFGKfoCbOXbsGOBITAsWLHD1zxw4cICDBw9y8OBBHnnkESZOnEiHDh1o3bo1S5Ys4cyZM5w5c4YlS5bQunVr1/lmzpxJjx493P7dpGdJV5X3ftjNE9M2UaFILr57phENKhb2dlgZjlvNRyJSEiiTfH9VXeOpoDKSoUOH8t///te1PH78ePr06cOYMWMoUqQIU6ZMAeDjjz8G4Iknnkhx/JNPPsmgQYMICgoia9asTJ069ZbfSLt3707//v0ZN25cqvMYjB49mi5dulCgQAGaN2/OgQMH/urbTKFkyZL885//pE6dOhQsWJAqVaq4mpiS+/DDD1m5cqVrVrkHH3yQCxcu8Le//Y2goCBCQ0OpUqXKbV8/ODiYZs2acerUKV599VVKlCiRonmpX79+HDx4kFq1aqGqFClShAULFrBq1SrGjBmDr68vuXPndt0p9OvXjyeeeILQ0JRFJYcNG0ZsbCxdunQBoHTp0ixatAhwJPPdu3cTGxuLv78/kydPpnXr1vTs2ZOTJ0+iqoSEhLj+v99IwYIFefXVV12JbeTIka5mOYDZs2ffcLa8jOT0xSs8O2sLP0WeokedUoz6WzVy+Pp4O6wM6Zals0XkPaAbsAtIcq5WVW3n4dhuKT2Vzs5sYmNjyZ07N4mJiXTs2JG+ffv+aU4GTxg9ejS5c+fmhRde8Pi10ov0/jexI+ocA7/axMkLl3m9fTW61ynt7ZDSvb9aOrsDUFlVL9/dsExGNnr0aJYtW0Z8fDytWrWiQ4cO3g7JpENzwo8wfMEOCuXKxuwn6hNSKr+3Q8rw3EkK+wFfwJKCcdvYsWO9cl1PPDlu7r0riVd5/budTFt/mPrlCzH+7zUpnPvWHfnmr7thUhCR8YACcUCEiCwnWWJQ1ZsPsPciVbXRCMZw41Fjadkf5+IZNH0TWw6fZWCT8gxrXZmsPjYm5l652Z3Ctcb6TcCiexDLXZEjRw5iYmIoVKiQJQaTqakqMTEx5MiRfiaU+XV/DE/N2EzclSQm/L0WDwUX93ZImc4Nk4KqfgEgIrmAeFVNci77AGn2Ps7f35+jR49y8uRJb4dijNflyJEDf/+0P4+AqvL5zwd5e/FvlCnox4z+9ahU7PbKhJi7w50+heVASyDWuZwTWAI08FRQf4Wvr+8Nn9A1xqQ9R8/E8c73u/nftmM8EFiMf3WtQd4cvt4OK9NyJynkUNVrCQFVjRURP3dOLiJDgH44+ia2A32AyUAokABsAAaqaoKINAUWAtcGzX+jqq+7+0aMMenL4Zg4Jq7ay9xNRxGBYa0rM+j+CmTJYs2+3uROUrgoIrVUdTOAiNQGLt3qIOcDb4OBQFW9JCKzge7AdOBR524zcCSNj5zLP6nqw386mTEmw9h/MpYJK/exICIKnyxCz7qlGXh/BUrkz3nrg43HuZMUngPmiEg0IMB9OB5mc/f8OUUkAfADolV1ybWNIrIBSPsNnsaYvyzy+AX+u3Iv326NJlvWLPRuUJYBTcpTLG/66QjPDG6ZFFR1o4hUAa4V3PldVRPcOC5KRMYCh3HcWSy5LiH4Ao8BzyY7rL6IbAWigRdUdef15xWRAcAAcJQVMMakbb8dO89/V+xl8Y5j5PT1oX/j8vRrXJ4iedLseJVM7ZZJwfnhPQho4ly1SkQ+uVViEJECQHugHHAWx93Go6o6zbnLRGCNql6byWQzUMbZZ9EWWAAEXH9eVZ0ETAJHmYtbxW+M8Y4dUecYtzySJbuOkzt7Vp5sWoF/NCpPQZsiM01zp/noIxxPNE90Lj/mXNfvFse1BA6o6kkAEfkGx4ilaSIyCigCDLy2s6qeT/Z6sYhMFJHCqnrK3TdjjPG+LYfPMH7FXlbsPkHeHFl5tkUAfRuWI5+fjShKD9xJCmGqWiPZ8gpnE8+tHAbqOUcqXQJaAOEi0g9oDbRQ1avXdhaR+4DjqqoiUgdHWe8Yd9+IMca7wg+e5j/LI/kp8hT5/Xx5oVUlHm9Q1oaXpjPuJIUkEamgqvsARKQ8/18t9YZU9VcRmYujWSgR2IKj2ecicAhY53zi+NrQ00eAQSKSiCOJdNf0+Iy+MZmIqrJ+/2nGLY9k3f4YCuXKxssPVuHRemXInd0mdkyP3Cmd3QKYgqMwnuCYV6GPqq70fHg3l1rpbGOM56kqa/eeYvzyvWw4eJoiebIzsEl5/l63NH7ZLBmkdX+pdLaqLheRAFKOPrKKqcZkQqrKqt9PMm5FJFsOn+W+vDl4rV01uoWVsklvMgh3Rh/lAJ4EGuF4MvknEflYVVOf2NcYk+GoKkt3HWf8ir1sjzpHyfw5eatjdR6p7U/2rJYMMhJ37vO+BC4A453Lfwe+Arp4KihjTNpw9aryw84/GL9iL78dO0/pgn683zmYjrVK4mvlrDMkd5JCdVUNTLa8UkR2eSogY4z3JV1VvtsWzYSVe9lzPJbyhXPxQdcatKtRwuY2yODcSQqbRaSeqq4HEJG6/P9cC8aYDCQx6SqLtkbz35V72X/yIgFFczOuR00eCiqOjxWqyxTcSQq1gV9E5LBzuTTwu4hsB1RVgz0WnTHmnkhIusr8zVFMWLWXQzFxVLkvDxN71qJNtfusamkm405SaOPxKIwxXnE5MYm5m44yceU+os5eIqhkPiY9VpuWVYtZMsik3BmSekhEGgEBqjpFRAoDeVT1wK2ONcakTfEJSXy98Qgfr97HsXPxhJTKz5sdqtO0chGbxjaTc2dI6igck+JUxvEQWzZgGtDQs6EZY+62S1eSmP7rIT5Zs5+TFy4TVrYA7z8STKOKhS0ZGMC95qOOQE0c5SpQ1WgRsclTjUlHLl5O5Kv1h/jsp/2cir1C/fKFGNe9JvXKF7RkYFJwJylccRapUwARyeXhmIwxd8n5+AS+/OUgk9ce4ExcAo0DCjO4RQBhZQt6OzSTRrmTFGaLyCdAfhHpD/QFPvVsWMaYv+JcXAKf/3yAKT8f4Hx8Is2rFOWZ5hWpWbqAt0MzaZw7Hc1jReQB4DyOfoWRqrrU45EZY27b6YtXmLx2P1/8cojYy4m0CizGM80DCPLP5+3QTDrhVjlDZxKwRGBMGnXywmU++2k/X60/xKWEJNpWL87TzStStXheb4dm0hmrcWtMOnbifDyfrNnP9F8PcSXxKn+rUYKnm1UkoJiNBTF3xpKCMelQ9NlLfLJ6HzM3HiHpqtIhpCRPNatA+SK5vR2aSedumhRExAf4UlV73qN4jDE3ceR0HB+t3sec8COowiO1/XmyaUVKF/Lzdmgmg7hpUlDVJBEpIyLZVPXKvQrKGJPSwVMXmbhqL99sjiKLCN3CSvHE/RXwL2DJwNxd7jQf7Qd+FpFFOOZXBkBVP/BYVMYYAPadjGXCir0siIjC1ycLj9Yrw8D7y1M8X05vh2YyKHeSwj7nTxbAeq+MuQf2HL/A+BV7+W5bNDmy+vCPRuXo36Q8RfPk8HZoJoNz5zmF1wBExE9V4zwfkjGZ187oc/x3xV6+3/EHubL5MLBJBfo1Lkfh3Nm9HZrJJNwpiFcfmAzkBkqLSA1goKo+6engjMksth09y7jle1n223HyZM/KM80r0rdhOQrkyubt0Ewm407z0YdAa2ARgKpuFZEmHo3KmExi06EzjF8RyarfT5Ivpy9DWlaid8Oy5Mvp6+3QTCbl7hPNR66rpJjkmXCMyRw2HDjNuOWRrN17igJ+vgxrXZnH65chTw5LBsa73EkKR0SkAaAi4gs8C/zm2bCMyXhUlXX7Yhi3IpL1+09TOHc2/tm2Cj3rliFXdnuO1KQN7vxLfAL4D1ASiAZ+BJ7yZFDGZCSqyprIU4xfHkn4oTMUzZOdkQ8H0qNOaXJm8/F2eMak4M7oo1OAPdFszG1SVVbsPsG4FXvZeuQsJfLl4I321egSWoocvpYMTNrkzuij8jjuFOoBCqwDhqjqfjeOHQL0cx63HeiDYyRTKJAAbMAxkilBHJ0W/wHaAnFAb1XdfCdvyhhvUlWW7DrOuOWR7Iw+j3+BnLzTKYjOtfzJljWLt8Mz5qbc+Rc6A5gNFAdKAHOAmbc6SERKAoOBUFWtDvgA3YHpQBUgCMiJI2kAPAgEOH8GAB/dzhsxJi04cjqOXlM2MvCrTVy8nMiYR4JZ+UJTetQpbQnBpAvu9Cn4qepXyZaniciw2zh/ThFJAPyAaFVdcm2jiGwA/J2L7XEU31NgvYjkF5HiqnrMzWsZ4zWJSVf5/OcDfLB0Dz4ijP5bII/WK0NWH0sEJn1xJyl8LyIvA7NwNAN1AxaLSEEAVT2d2kGqGiUiY4HDwCVgyXUJwRd4DMdoJnB0ZB9JdoqjznUpkoKIDMBxJ0Hp0qXdCN8Yz9p29Cwvz9vOrmPnaVm1GK+3r0aJ/FabyKRP7iSFrs7/DrxufXccSaJ8ageJSAEc3/7LAWeBOSLyqKpOc+4yEVijqj/dTsCqOgmYBBAaGqq3c6wxd9PFy4l8sHQPU34+QOHc2fmoZy3aVL+P657pMSZdcWf0Ubk7PHdL4ICqngQQkW+ABjian0YBRUiZaKKAUsmW/Z3rjElzVu4+wYgFO4g6e4medUvzYpsq9hSyyRA8+cTMYaCeiPjhaD5qAYSLSD8cZTNaqOrVZPsvAp4WkVlAXeCc9SeYtObkhcu8/t0uvt0aTcWiuZnzRH3Cyhb0dljG3DUeSwqq+quIzAU2A4nAFhzNPheBQ8A65232N6r6OrAYx3DUvTiGpPbxVGzG3C5VZXb4Ed7632/EJ1zl+QcqMfD+8mTPas8bmIzFo8/Wq+ooYJQ713SOOrInpU2as+9kLP/8Zju/HjhNnXIFeadTEBVsLmSTQbnz8No3OB44+/665h5jMrQriVf5ePU+/rtiLzl8s/BupyC6hpYiSxbrSDYZlzt3ChNxNOWME5E5wBRV/d2zYRnjXZsOnebleduJPBHLw8HFGfm3QJv1zGQK7ow+WgYsE5F8QA/n6yPAp8A0VU3wcIzG3DPn4xN4/4fdTFt/mJL5c/J571CaVynm7bCMuWfc6lMQkULAozgeNtuCo1RFI6AX0NRTwRlzr6gqP+78g5ELd3Iq9jL/aFSO5x+oZCWtTabjTp/CfKAy8BXwt2TDRL8WkXBPBmfMvXDs3CVGLtzJ0l3HCSyel896hRLsn9/bYRnjFe58DRqnqitT26CqoXc5HmPumaSryrT1hxjz4+8kXr3KKw9WoW+jcvhavSKTibmTFAJFZIuqngVX+YoeqjrRs6EZ4zm7/zjPK99sZ8vhszQOKMxbHYIoXcjP22EZ43XuJIX+qjrh2oKqnhGR/jhGJRmTrsQnJDF+RSSfrN5P3py+fNgthPYhJaxekTFO7iQFHxER58NliIgPkM2zYRlz9/2y9xT/nL+dgzFxdK7lz/CHqlIwl/1TNiY5d5LCDzg6lT9xLg90rjMmXThz8QpvLf6NuZuOUqaQH9P71aVhxcLeDsuYNMmdpPASjkQwyLm8FPjMYxEZc5eoKgsjonn9u12cv5TAk00rMLhFgM2PbMxNuPPw2lUcU2Pa9Jgm3ThyOo7hC3awZs9JapTKz7udgqhaPK+3wzImzXPnOYUA4B0gEHA956+qqU6uY4w3pTYt5mP1y+Jj9YqMcYs7zUdTcFQ6/TfQDEcdJBvIbdKcbUfP8so329kZbdNiGnOn3EkKOVV1uXME0iFgtIhsAkZ6ODZj3GLTYhpz97iTFC6LSBYgUkSexjFFphWTN2mCTYtpzN3lTlJ4FvADBgNv4GhC6uXJoIy5FZsW0xjPuGlScD6o1k1VXwBisSkyjZddPy3mkJaVeKKpTYtpzN1y06Sgqkki0uheBWPMzVw/LebbHYOoWNRaMo25m9xpPtoiIouAOcDFaytV9RuPRWVMMjYtpjH3jjtJIQcQAzRPtk4BSwrG42xaTGPuLXeeaLZ+BHPP2bSYxniHO080T8FxZ5CCqvb1SEQm0/thxzHXtJh9G5ZjaCubFtOYe8Wdv7Tvkr3OAXQEoj0TjsnMkk+LWbV4Xj59PJQapWxaTGPuJXeaj+YlXxaRmcBaj0VkMh2bFtOYtONO7skDgKJ3OxCTOdm0mMakLe70KVwgZZ/CHzjmWDDmjtm0mMakTe40H+W505OLyBCgH46ksh3HE9H9gOeACkARVT3l3LcpsBA44Dz8G1V9/U6vbdIumxbTmLTLnTuFjsAKVT3nXM4PNFXVBbc4riSOekmBqnpJRGYD3YGfcXRer0rlsJ9U9eHbewsmvbBpMY1J+9zpUxilqvOvLajqWREZBdw0KSQ7f04RScBRVC9aVbcA1kyQidi0mMakH+4khdSGgLjT7BQlImOBw8AlYImqLrnFYfVFZCuOIa8vqOrO63cQkQHAAIDSpUvfKgzjZTYtpjHpiztJIVxEPgAmOJefAjbd6iARKQC0B8oBZ4E5IvKoqk67wSGbgTKqGisibXHciQRcv5OqTgImAYSGhv7poTqTNti0mMakT+4MBH8GuAJ8DcwC4nEkhltpCRxQ1ZOqmoCjVlKDG+2squdVNdb5ejHgKyLW4JwObT96jvYTfubtxbtpVLEwS5+/n94Ny1lCMCYdcKcZ6CLw8h2c+zBQT0T8cDQftQDCb7SziNwHHFdVFZE6OBJWzB1c13iJTYtpTPrnzuijpUAXVT3rXC4AzFLV1jc7TlV/FZG5OJqFEoEtwCQRGQy8CNwHbBORxaraD3gEGCQiiTiSSHdVteahdMKmxTQmY5Bbfe6KyBZVrXmrdd4QGhqq4eE3vPkw98D102K+0ynIpsU0Jo0TkU2qGpraNnc6mq+KSGlVPew8WRlSqZpqMhebFtOYjMmdpDAcWCsiqwEBGuMcEmoyp/0nY3nl2rSYZQvydiebFtOYjMKdjuYfRKQWUM+56rlrpSlM5nIl8SqfrN7H+JV7yZHVpsU0JiNyt0pqEnACx3wKgSKCqq7xXFgmrbFpMY3JHNwZfdQPeBbwByJw3DGsI+WczSaDik9IYsyPv/P5zwcokc+mxTQmo3PnTuFZIAxYr6rNRKQK8LZnwzJpwbajZ3l+9lb2nojlsXplePnBKjYtpjEZnDt/4fGqGi8iiEh2Vd0tIpU9HpnxmoSkq0xYuZfxK/ZSJHd2vuxbhyaVing7LGPMPeBOUjjqLJe9AFgqImeAQ54Ny3jL3hOxPD87gm1Hz9EhpASvtatOPj97CM2YzMKd0UcdnS9Hi8hKIB/wg0ejMvfc1avK1F8O8t4Pu/HL5sPEnrVoG1Tc22EZY+6x22ogVtXVngrEeM/RM3EMm7ONdftjaFGlKO90DrKRRcZkUtZrmImpKnM3HeW1b3ehqrzX2fHcgRWwMybzsqSQSZ2Kvcwr32xn6a7j1ClXkH91qUGpgn7eDssY42WWFDKhH3b8wfD527lwOZERD1Wlb8Ny9lSyMQawpJCpnI9PYPSinXyzOYrqJfMys2sIlYrl8XZYxpg0xJJCJvHz3lMMm7OV4xcuM7h5RZ5pEYCvjzsT7xljMhNLChncpStJvPfDbqb+cpDyhXMxb1ADQkrl93ZYxpg0ypJCBhZx5CzPz45g/8mL9G5QlpfaVCFnNpvvwBhzY5YUMqCEpKuMXx7JhFX7KJYnO9P71aVhxcLeDssYkw5YUshg9hy/wPOzI9gRdZ7OtfwZ1S6QvDmsTIUxxj2WFDKIpKvK52sPMGbJ7+TOnpWPH61Nm+r3eTssY0w6Y0khAzhyOo6hc7ay4cBpHggsxtsdgyiSJ7u3wzLGpEOWFNIxVWV2+BFe/3YXIsKYR4J5pLa/lakwxtwxSwrp1IkL8bwybzvLd5+gfvlCjOkSjH8BK1NhjPlrLCmkQ4u3H2P4/O3EXUli5MOB9G5Q1spUGGPuCksK6ci5uARGLdrBgohogv3z8UHXGlQsamUqjDF3jyWFdGLNnpO8OHcbJ2Mv81zLAJ5qVtHKVBhj7jpLCmlc3JVE3lm8m6/WH6Ji0dxMerw2wf5WpsIY4xke/aopIkNEZKeI7BCRmSKSQ0SeFpG9IqIiUjjZviIi45zbtolILU/Glh5sOnSGtv/5iWm/HuIfjcrx3TONLCEYYzzKY3cKIlISGAwEquolEZkNdAd+Br4DVl13yINAgPOnLvCR87+ZzpXEq/xn+R4+WrWP4vlyMqNfPepXKOTtsIwxmYCnm4+yAjlFJAHwA6JVdQuQ2lj69sCXqqrAehHJLyLFVfWYh2NMU3b/cZ4hX2/lt2Pn6Rrqz6sPB5LHylQYY+4RjyUFVY0SkbHAYeASsERVl9zkkJLAkWTLR53rUiQFERkADAAoXbr0XY3Zm5KuKp/+tJ8Pluwhb86sfPp4KA8EFvN2WMaYTMZjfQoiUgDHt/9yQAkgl4g8+lfPq6qTVDVUVUOLFCnyV0+XJhyKuUi3T9bx7ve7aV6lKD8+18QSgjHGKzzZfNQSOKCqJwFE5BugATDtBvtHAaWSLfs712VYqsrMDUd483+78Mki/LtbDTqElLQyFcYYr/FkUjgM1BMRPxzNRy2A8Jvsvwh4WkRm4ehgPpeR+xOOn4/npXnbWPX7SRpVLMz7jwRTIn9Ob4dljMnkPNmn8KuIzAU2A4nAFmCSiAwGXgTuA7aJyGJV7QcsBtoCe4E4oI+nYvO2b7dGM2LBDi4nJvFau2o8Vq+MlakwxqQJ4hjskz6FhoZqePjNbj7SlrNxV3h14U6+3RpNSKn8fNC1BuWL5PZ2WMaYTEZENqlqaGrb7Inme2Tl7yd4ae42Tl+8wgutKvHE/RXIamUqjDFpjCUFD7t4OZG3Fv/GjF8PU6lYbj7vHUb1kvm8HZYxxqTKkoIHhR88zfOzt3LkTBwDm5RnyAOVyOHr4+2wjDHmhiwpeMDlxCQ+WLqHSWv2418gJ18PqE+dcgW9HZYxxtySJYW7bGf0OYbO3sruPy7Qo04phj8USO7s9ms2xqQP9ml1lyQmXeWTNfv5cNke8vtl4/PeoTSvYk8lG2PSF0sKd8GBUxd5fnYEWw6f5aGg4rzZoToFcmXzdljGGHPbLCn8BarKtPWHeHvxbnx9hP90D6FdjRJWpsIYk25ZUrhDx85d4sW52/gp8hRNKhXh/c7B3Jcvh7fDMsaYv8SSwm1SVRZGRDNy4Q4SkpQ3O1SnZ93SdndgjMkQLCnchtMXrzBiwXYWb/+DWqXz80HXEMoWzuXtsIwx5q6xpOCm5b8d56V52zl36QovtqnMwCYV8LEidsaYDMaSwi3EXk7kze92MWvjEarcl4cv+9YhsEReb4dljDEeYUnhJn7dH8PQOVuJPnuJQU0r8FzLALJntTIVxpiMy5JCKuITkvjXkt/5bO0BShf0Y/bA+oSWtTIVxpiMz5LCdXZEnWPI1xFEnoilZ93S/LNtVXJZmQpjTCZhn3ZOiUlXmbhqH+OWR1Iodzam9gmj6f+1d/+xVtd1HMefL+Emv0yIH4WAQLm5hBDIGEU5g2ppDlzSZCZJP2Y/3MjcqtEsl3MrW8tWtiHDNkhAlKCQ1GXKaLbE+CmE1MhIMTZuJBhlTODdH9/PPZ4O59577u1+v9/Tva/Hdrdzz/fzPZ/X/bAv73O+53zf5+JRZccyMyuUiwLwp9YT3Prgbna/eIy5l17AM9J2IAAAB4tJREFUHfMmMXSQ21SYWd/Tp4vCmTPByt8e5NuP7WdASz/uuX4aV0+5oOxYZmal6bNF4a/HXuXL63bzmwNHef/FI7nr2imMeqPbVJhZ39Yni8LmPxxh8eqdnI7gWx99BwveNc5tKszM6KNFYeLwwUwbP4w7503mwuGDyo5jZtY0+mRRmDBiMCs/NaPsGGZmTeecsgOYmVnzcFEwM7MKFwUzM6twUTAzs4pci4KkL0n6vaS9ktZIGiBpoqStkg5IWivpDWnsIkmtknaln8/kmc3MzM6WW1GQNAZYDFwWEZOBfsAC4C7g7oi4CHgZ+HTVbmsjYmr6WZ5XNjMzqy/v00f9gYGS+gODgMPAbGBd2r4CuCbnDGZm1qDcikJEvAR8F3iBrBgcB7YDxyLiVBp2CBhTtdu1kp6VtE7SuHqPK+kmSdskbWttbc0rvplZn5TbxWuShgHzgInAMeAh4MMd7PIwsCYiTkr6LNmriNm1gyJiGbAszdEq6S/djDgC+Fs3981Ts+aC5s3mXF3jXF3TG3ONb29Dnlc0fwD4c0S0AkhaD8wChkrqn14tjAVeAoiIo1X7Lge+09kEETGyu+EkbYuIy7q7f16aNRc0bzbn6hrn6pq+livP9xReAGZKGqSs29wcYB+wGZifxtwI/BxA0uiqfecCz+WYzczM6sjtlUJEbJW0DtgBnAJ2kp32+QXwgKQ70333pV0WS5qbxv4dWJRXNjMzqy/XhngRcTtwe83dzwNndaOLiCXAkjzz1FhW4Fxd0ay5oHmzOVfXOFfX9Klciog8HtfMzP4Puc2FmZlVuCiYmVlFry8Kkn4s6Yikve1sl6QfpF5Mz0qa3iS5rpB0vKoX1DcKyDRO0mZJ+1LPqi/WGVP4ejWYq4z1GiDpGUm7U65v1hlzburxdSD1/JrQJLlK6zUmqZ+knZI21dlW+Ho1mKvM9TooaU+ad1ud7T17TEZEr/4BLgemA3vb2X4V8CggYCawtUlyXQFsKnitRgPT0+3zgD8Cl5S9Xg3mKmO9BAxJt1uArcDMmjFfAJam2wvI+ns1Q65FwD1FrlfV3LcCq+v9e5WxXg3mKnO9DgIjOtjeo8dkr3+lEBG/JvuIa3vmASsj8zTZxXWjOxhfVK7CRcThiNiRbv+D7FqRMTXDCl+vBnMVLq3BifRrS/qp/eTGPLKr8yHr+TUnXbdTdq5SSBoLfITsAtV6Cl+vBnM1sx49Jnt9UWjAGODFqt9r+zGV6d3pFMCjkiYVOXF62T6N7FlmtVLXq4NcUMJ6pVMOu4AjwOMR0e56RXYV/3FgeBPkggZ6jeXg+8BXgDPtbC9lvRrIBeWsF2QF/ZeStku6qc72Hj0mXRSa1w5gfERcCvwQ+FlRE0saAvwUuCUiXilq3s50kquU9YqI0xExlaxlywxJk4uYtzMN5HoYmBARU4DHef3ZeW4kXQ0ciYjtec/VFQ3mKny9qrw3IqYDVwI3S7o8z8lcFLLeS9VVv9KPqUwR8UrbKYCIeARokTQi73kltZD9x7sqItbXGVLKenWWq6z1qpr/GFkLl9qmj5X1UtZC/nzgKAVpL1dEHI2Ik+nX5cA7C4gzC5gr6SDwADBb0v01Y8pYr05zlbRebXO39Yc7Amzg7It/e/SYdFGAjcAn0jv4M4HjEXG47FCS3tJ2LlXSDLJ/q1wPjjTffcBzEfG9doYVvl6N5CppvUZKGppuDwQ+COyvGbaRrMcXZD2/noz07mCZuVRCr7GIWBIRYyNiAtmbyE9GxA01wwpfr0ZylbFead7Bks5ruw18CKj9xGKPHpO5trloBpLWkH0yZYSkQ2RtN1oAImIp8AjZu/cHgH8Bn2ySXPOBz0s6BbwKLMj74CB7xrQQ2JPORwN8DbiwKlcZ69VIrjLWazSwQlI/siL0YERsknQHsC0iNpIVs59IOkD2wYIFOWdqNFfT9BprgvVqJFdZ6/VmYEN6vtMfWB0Rj0n6HORzTLrNhZmZVfj0kZmZVbgomJlZhYuCmZlVuCiYmVmFi4KZmVW4KJiVRFln17M6cpqVyUXBzMwqXBTMOiHpBmXfT7BL0r2p2dwJSXcr+76CJySNTGOnSno6NU7bIGlYuv8iSb9KDft2SHpbevghqcHafkmriugIatYRFwWzDkh6O3AdMCs1mDsNfBwYTHa16yRgC9kV6QArga+mxml7qu5fBfwoNex7D9DWhmAacAtwCfBWsqu3zUrT69tcmP2P5pA1P/tdehI/kKwd9RlgbRpzP7Be0vnA0IjYku5fATyUeteMiYgNABHxb4D0eM9ExKH0+y5gAvBU/n+WWX0uCmYdE7AiIpb8153S12vGdbdfzMmq26fxMWkl8+kjs449AcyXNApA0pskjSc7duanMdcDT0XEceBlSe9L9y8EtqRvizsk6Zr0GOdKGlToX2HWID8rMetAROyTdBvZN1+dA7wG3Az8k+zLa24jO510XdrlRmBp+k//eV7vWLkQuDd13nwN+FiBf4ZZw9wl1awbJJ2IiCFl5zDraT59ZGZmFX6lYGZmFX6lYGZmFS4KZmZW4aJgZmYVLgpmZlbhomBmZhX/Aa0JQ8BSpRKSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udbOZqci4s2q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}